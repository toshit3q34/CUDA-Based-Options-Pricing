{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "%ls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kN8kcCTNGNng",
        "outputId": "128f1305-7fe0-4e87-8b0a-5a52b4468d20"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[0m\u001b[01;34msample_data\u001b[0m/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 76
        },
        "id": "kma3Ssn7Jimj",
        "outputId": "5468c79b-e72f-4111-80d0-984b1c4e839f"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-b8e2782d-c4d3-47e1-bd8a-a3dcf02ba7ef\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-b8e2782d-c4d3-47e1-bd8a-a3dcf02ba7ef\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving C++ Multitheading.zip to C++ Multitheading.zip\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4EuyVi6zTmUQ",
        "outputId": "f5b4bfed-df3a-4aaf-9f2f-9f87e0cc1f33"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sat Jun 28 19:50:16 2025       \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 550.54.15              Driver Version: 550.54.15      CUDA Version: 12.4     |\n",
            "|-----------------------------------------+------------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                        |               MIG M. |\n",
            "|=========================================+========================+======================|\n",
            "|   0  Tesla T4                       Off |   00000000:00:04.0 Off |                    0 |\n",
            "| N/A   45C    P8              9W /   70W |       0MiB /  15360MiB |      0%      Default |\n",
            "|                                         |                        |                  N/A |\n",
            "+-----------------------------------------+------------------------+----------------------+\n",
            "                                                                                         \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                              |\n",
            "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
            "|        ID   ID                                                               Usage      |\n",
            "|=========================================================================================|\n",
            "|  No running processes found                                                             |\n",
            "+-----------------------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd C++\\ Multitheading\n",
        "%ls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jrVIEVOlpeZq",
        "outputId": "4b4823cd-daf5-46fa-eafd-00efe213123d"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/C++ Multitheading\n",
            "\u001b[0m\u001b[01;34mbenchmarking\u001b[0m/  \u001b[01;34minclude\u001b[0m/  README.md  \u001b[01;34msrc\u001b[0m/  \u001b[01;34mthird_party\u001b[0m/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvcc -std=c++17 -arch=sm_75 \\\n",
        "  -Iinclude \\\n",
        "  benchmarking/european.cu src/european.cu \\\n",
        "  -o benchmark"
      ],
      "metadata": {
        "id": "3D33F0XFKXU_"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!./benchmark"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q6FxOoY0yFcY",
        "outputId": "ae781f84-4aa8-48ee-a921-c7c7335a9509"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0. European Call GPU took 0.608182 seconds.\n",
            "1. European Call GPU took 0.38299 seconds.\n",
            "2. European Call GPU took 0.384577 seconds.\n",
            "3. European Call GPU took 0.382407 seconds.\n",
            "4. European Call GPU took 0.384733 seconds.\n",
            "5. European Call GPU took 0.383999 seconds.\n",
            "6. European Call GPU took 0.383365 seconds.\n",
            "7. European Call GPU took 0.388515 seconds.\n",
            "8. European Call GPU took 0.380252 seconds.\n",
            "9. European Call GPU took 0.381576 seconds.\n",
            "10. European Call GPU took 0.383794 seconds.\n",
            "11. European Call GPU took 0.387002 seconds.\n",
            "12. European Call GPU took 0.389111 seconds.\n",
            "13. European Call GPU took 0.386408 seconds.\n",
            "14. European Call GPU took 0.384598 seconds.\n",
            "15. European Call GPU took 0.392357 seconds.\n",
            "16. European Call GPU took 0.383675 seconds.\n",
            "17. European Call GPU took 0.384278 seconds.\n",
            "18. European Call GPU took 0.386072 seconds.\n",
            "19. European Call GPU took 0.381894 seconds.\n",
            "20. European Call GPU took 0.392825 seconds.\n",
            "21. European Call GPU took 0.382112 seconds.\n",
            "22. European Call GPU took 0.381921 seconds.\n",
            "23. European Call GPU took 0.390686 seconds.\n",
            "24. European Call GPU took 0.3931 seconds.\n",
            "25. European Call GPU took 0.431412 seconds.\n",
            "26. European Call GPU took 0.432828 seconds.\n",
            "27. European Call GPU took 0.426863 seconds.\n",
            "28. European Call GPU took 0.452413 seconds.\n",
            "29. European Call GPU took 0.388455 seconds.\n",
            "30. European Call GPU took 0.383595 seconds.\n",
            "\n",
            "Average time for European Call GPU: 0.39226 seconds.\n",
            "Average time for European Call CPU: 1.10423 seconds.\n",
            "European Call CPU took 1.10427 seconds.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvcc -std=c++17 -arch=sm_75 \\\n",
        "  -Iinclude \\\n",
        "  benchmarking/asian.cu src/asian.cu \\\n",
        "  -o benchmark"
      ],
      "metadata": {
        "id": "X7NibEpKHXJc"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!./benchmark"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eNXCJ_XiHY-H",
        "outputId": "5549762d-f941-4b55-cdbb-da93ba2f297e"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0. Asian Call GPU took 0.373532 seconds.\n",
            "1. Asian Call GPU took 0.163472 seconds.\n",
            "2. Asian Call GPU took 0.139761 seconds.\n",
            "3. Asian Call GPU took 0.139311 seconds.\n",
            "4. Asian Call GPU took 0.139462 seconds.\n",
            "5. Asian Call GPU took 0.139342 seconds.\n",
            "6. Asian Call GPU took 0.139249 seconds.\n",
            "7. Asian Call GPU took 0.139347 seconds.\n",
            "8. Asian Call GPU took 0.139243 seconds.\n",
            "9. Asian Call GPU took 0.139352 seconds.\n",
            "10. Asian Call GPU took 0.13923 seconds.\n",
            "11. Asian Call GPU took 0.139274 seconds.\n",
            "12. Asian Call GPU took 0.13909 seconds.\n",
            "13. Asian Call GPU took 0.139791 seconds.\n",
            "14. Asian Call GPU took 0.141304 seconds.\n",
            "15. Asian Call GPU took 0.139356 seconds.\n",
            "16. Asian Call GPU took 0.139412 seconds.\n",
            "17. Asian Call GPU took 0.139947 seconds.\n",
            "18. Asian Call GPU took 0.141283 seconds.\n",
            "19. Asian Call GPU took 0.139311 seconds.\n",
            "20. Asian Call GPU took 0.139512 seconds.\n",
            "21. Asian Call GPU took 0.139477 seconds.\n",
            "22. Asian Call GPU took 0.139261 seconds.\n",
            "23. Asian Call GPU took 0.13991 seconds.\n",
            "24. Asian Call GPU took 0.139487 seconds.\n",
            "25. Asian Call GPU took 0.139294 seconds.\n",
            "26. Asian Call GPU took 0.139646 seconds.\n",
            "27. Asian Call GPU took 0.139192 seconds.\n",
            "28. Asian Call GPU took 0.139377 seconds.\n",
            "29. Asian Call GPU took 0.13923 seconds.\n",
            "30. Asian Call GPU took 0.139386 seconds.\n",
            "\n",
            "Average time for Asian Call GPU: 0.140343 seconds.\n",
            "Average time for Asian Call CPU: 26.7073 seconds.\n",
            "Asian Call CPU took 26.7074 seconds.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvcc -std=c++17 -arch=sm_75 \\\n",
        "  -Iinclude \\\n",
        "  benchmarking/basket.cu src/basket.cu \\\n",
        "  -o benchmark"
      ],
      "metadata": {
        "id": "vjQs4MkzH0D2"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!./benchmark"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GYBUEFhGH3Y-",
        "outputId": "662aad15-86e7-4900-bf54-d5bef5b04a56"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0. Basket Call GPU took 0.695314 seconds.\n",
            "1. Basket Call GPU took 0.408541 seconds.\n",
            "2. Basket Call GPU took 0.409821 seconds.\n",
            "3. Basket Call GPU took 0.413869 seconds.\n",
            "4. Basket Call GPU took 0.414119 seconds.\n",
            "5. Basket Call GPU took 0.412344 seconds.\n",
            "6. Basket Call GPU took 0.413103 seconds.\n",
            "7. Basket Call GPU took 0.411377 seconds.\n",
            "8. Basket Call GPU took 0.415676 seconds.\n",
            "9. Basket Call GPU took 0.412717 seconds.\n",
            "10. Basket Call GPU took 0.411702 seconds.\n",
            "11. Basket Call GPU took 0.411082 seconds.\n",
            "12. Basket Call GPU took 0.412126 seconds.\n",
            "13. Basket Call GPU took 0.4145 seconds.\n",
            "14. Basket Call GPU took 0.414098 seconds.\n",
            "15. Basket Call GPU took 0.411254 seconds.\n",
            "16. Basket Call GPU took 0.41474 seconds.\n",
            "17. Basket Call GPU took 0.410633 seconds.\n",
            "18. Basket Call GPU took 0.414303 seconds.\n",
            "19. Basket Call GPU took 0.410851 seconds.\n",
            "20. Basket Call GPU took 0.412082 seconds.\n",
            "21. Basket Call GPU took 0.413335 seconds.\n",
            "22. Basket Call GPU took 0.411462 seconds.\n",
            "23. Basket Call GPU took 0.416742 seconds.\n",
            "24. Basket Call GPU took 0.4658 seconds.\n",
            "25. Basket Call GPU took 0.470857 seconds.\n",
            "26. Basket Call GPU took 0.460008 seconds.\n",
            "27. Basket Call GPU took 0.464567 seconds.\n",
            "28. Basket Call GPU took 0.455929 seconds.\n",
            "29. Basket Call GPU took 0.411848 seconds.\n",
            "30. Basket Call GPU took 0.414378 seconds.\n",
            "\n",
            "Average time for Basket Call GPU: 0.421128 seconds.\n",
            "Average time for Basket Call CPU: 37.1793 seconds.\n",
            "Basket Call CPU took 37.1793 seconds.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvcc -std=c++17 -arch=sm_75 \\\n",
        "  -Iinclude \\\n",
        "  benchmarking/american.cu src/american.cu \\\n",
        "  -o benchmark"
      ],
      "metadata": {
        "id": "mokbDTbAINad"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!./benchmark"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bBYocM9AIPn8",
        "outputId": "c439d8f7-aa4e-4b70-9965-41339fbacccd"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "American Put CPU took 26.7016 seconds.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvcc -std=c++17 -arch=sm_75 \\\n",
        "  -Iinclude -Ithird_party/cxxopts\\\n",
        "  src/main.cu src/european.cu src/asian.cu src/basket.cu src/american.cu \\\n",
        "  -o option_pricer"
      ],
      "metadata": {
        "id": "X6N3k-HrIewA"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!./option_pricer --type=european --payoff=call --method=gpu --paths=10000000"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jpD0pgdnNd_0",
        "outputId": "64097f8b-5444-4f9b-c9a0-76abbb97fd06"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Price: 10.4553\n",
            "European Call gpu took 0.62707 seconds.\n"
          ]
        }
      ]
    }
  ]
}